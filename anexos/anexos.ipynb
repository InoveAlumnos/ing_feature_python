{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfmpaR+qHfbPcxuuVuOmQ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n","\n","\n","# Ingeniería de feature\n","\n","Programa creado para mostrar ejemplos prácticos de los visto durante la clase<br>\n","v1.1"],"metadata":{"id":"LDqFi9Pqt9cI"}},{"cell_type":"markdown","source":["#### Ejemplo de código para Binary Encoding"],"metadata":{"id":"KgANwfQmuDax"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JuosxZEt6v_"},"outputs":[],"source":["class BinaryEncoder():\n","    def __init__(self):\n","        self.n_bits = 0\n","    \n","    def fit(self, data):\n","        if data.__class__.__name__ == list.__name__:\n","            self.n_bits = int(np.ceil(np.log2(max(data)+1))) + 1\n","        elif type(data).__module__ == pd.core.series.__name__:          \n","            self.n_bits = int(np.ceil(np.log2(data.max()+1))) + 1\n","        elif type(data).__module__ == np.__name__:\n","            self.n_bits = int(np.ceil(np.log2(data.max()+1))) + 1\n","        else:\n","            raise ValueError(\"Allowed list, numpy or pandas serie data\")\n","\n","    def transform(self, data):\n","        binary_encoding = [format(int(x+1), '0'+str(self.n_bits)+'b') for x in data]\n","        binary_encoding_split = [list(x) for x in binary_encoding]\n","        binary_encoding_header = ['b'+str(x) for x in reversed(range(self.n_bits))]\n","        return pd.DataFrame(binary_encoding_split, columns=binary_encoding_header, dtype=int)\n","\n","    def fit_transform(self, data):\n","        self.fit(data)\n","        return self.transform(data)"]},{"cell_type":"code","source":["# Implementación de Binary Encoding\n","# Copia\n","df5 = df3.copy()\n","\n","# Crear el encoder\n","be = BinaryEncoder()\n","\n","# Entrenar el encoder\n","be_df = be.fit_transform(df5['Nationality_LE'])\n","be_df"],"metadata":{"id":"LnUI8-yauKa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df5 = df5.join(be_df)\n","df5"],"metadata":{"id":"NHixZIDauRpo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Codificar un nuevo valor para nationality"],"metadata":{"id":"Z20LzOctttXZ"}},{"cell_type":"code","source":["# Nuevo valor\n","label = 'Holanda'\n","\n","# Transformación a binary encoding\n","b_encoding = be.transform(l_encoding)\n","print('BinaryEncoder:\\n', b_encoding)"],"metadata":{"id":"E51tRtIYtmZZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 - Estandarización y normalización"],"metadata":{"id":"lFuG84usuG9g"}},{"cell_type":"code","source":["# Datos que utilizaremos para ensayar\n","# Datos con una distribución normal\n","n1 = np.random.normal(loc=1000, scale=200, size=(1000))\n","n2 = np.random.normal(loc=1400, scale=50, size=(100))\n","n3 = np.random.normal(loc=2000, scale=50, size=(50))\n","data = np.append(n1, n2)\n","data_n = np.append(data, n3)\n","\n","# Datos con una distribución uniforme\n","n1 = np.linspace(500, 1000, 1000)\n","n2 = np.linspace(1800, 2200, 100)\n","data_u = np.append(n1, n2)"],"metadata":{"id":"QldL0G22uKEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_scalers(normal, uniform):\n","    fig = plt.figure(figsize=(16,3))\n","    ax1 = fig.add_subplot(1,2,1)\n","    ax2 = fig.add_subplot(1,2,2)\n","    ax1 = sns.distplot(normal, label='normal', ax=ax1)\n","    ax2 = sns.distplot(uniform, label='uniform', ax=ax2)\n","    ax1.legend()\n","    ax2.legend()\n","    plt.show()"],"metadata":{"id":"iAeYeE00uir5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_scalers(data_n, data_u)"],"metadata":{"id":"6TwIW2hDullw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejemplo de normalización y estandarización"],"metadata":{"id":"gPOr6ZfV6yWb"}},{"cell_type":"markdown","source":["#### StandardScaler (estandarización)"],"metadata":{"id":"2E1dBZSKuoix"}},{"cell_type":"code","source":["# Se importa la herramienta de sklearn.preprocessing\n","from sklearn.preprocessing import StandardScaler\n","\n","# Se crean los objetos scaler\n","scaler1_n = StandardScaler()\n","scaler1_u = StandardScaler()\n","\n","# Se implementa el método fit_transform()\n","data_n_standar = scaler1_n.fit_transform(data_n.reshape(-1, 1))\n","data_u_standar = scaler1_u.fit_transform(data_u.reshape(-1, 1))\n","\n","# Rerepesenta graficamente la estandarización de ambas variables\n","plot_scalers(data_n_standar, data_u_standar)"],"metadata":{"id":"W62yr8iFupi4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### MinMaxScaler (normalización)"],"metadata":{"id":"Hgz5csL4uwsp"}},{"cell_type":"code","source":["# Se importa la herramienta de sklearn.preprocessing\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Se crean los objetos scaler\n","scaler2_n = MinMaxScaler()\n","scaler2_u = MinMaxScaler()\n","\n","# Se implementa el método fit_transform()\n","data_n_norm = scaler2_n.fit_transform(data_n.reshape(-1, 1))\n","data_u_norm = scaler2_u.fit_transform(data_u.reshape(-1, 1))\n","\n","# Rerepesenta graficamente la normalización de ambas variables\n","plot_scalers(data_n_norm, data_u_norm)"],"metadata":{"id":"uhGCA9CiuxwA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### RobustScaler (estandarización)"],"metadata":{"id":"4pIVp74zu6-x"}},{"cell_type":"code","source":["# Se importa la herramienta de sklearn.preprocessing\n","from sklearn.preprocessing import RobustScaler\n","\n","# Se crean los objetos scaler\n","scaler3_n = RobustScaler()\n","scaler3_u = RobustScaler()\n","\n","# Se implementa el método fit_transform()\n","data_n_robust = scaler3_n.fit_transform(data_n.reshape(-1, 1))\n","data_u_robust = scaler3_u.fit_transform(data_u.reshape(-1, 1))\n","\n","# Rerepesenta graficamente la estandarización de ambas variables\n","plot_scalers(data_n_robust, data_u_robust)"],"metadata":{"id":"m8-G7NzFu7rp"},"execution_count":null,"outputs":[]}]}